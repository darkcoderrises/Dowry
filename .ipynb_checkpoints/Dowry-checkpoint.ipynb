{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "from scipy.stats import chi2_contingency as chi\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader = lambda i : list(filter(bool, open(i).read().split('\\n')))\n",
    "file_in = reader('in')\n",
    "words_list = reader('mark1/in1')\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "words_stopless = np.asarray(list(filter(lambda i: i not in stop, words_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix = np.zeros((len(file_in), len(words_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_file(file_content):\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    file_content = file_content.replace('\\r', ' ').lower()\n",
    "    return regex.sub(' ', file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count(file_content, word):\n",
    "    file_content = filter_file(file_content)\n",
    "    return sum(1 for _ in re.finditer(r'\\b%s\\b' % re.escape(' '+word+' '), file_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.95316159250585 %   \r"
     ]
    }
   ],
   "source": [
    "for i, file_name in enumerate(file_in):\n",
    "    sys.stdout.flush()\n",
    "    print (100*float(i)/len(file_in), '%', '\\r', end='')\n",
    "    \n",
    "    for j, word in enumerate(words_list):\n",
    "        file_content = open(str(file_name)).read()\n",
    "        matrix[i][j] = count(file_content, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix = np.asarray(matrix, dtype=np.float32)\n",
    "norm_matrix = matrix / (matrix.sum(axis=0)+0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_similarity(ind1, ind2):\n",
    "    vect1 = norm_matrix[:,ind1]\n",
    "    vect2 = norm_matrix[:,ind2]\n",
    "    inds = np.where(np.logical_or(vect1>0, vect2>0))\n",
    "    \n",
    "    return np.linalg.norm(vect1[inds]-vect2[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_similar_to(search_word):\n",
    "    vals = []\n",
    "    search_ind = words_list.index(search_word)\n",
    "    \n",
    "    for word in words_stopless:\n",
    "        value = return_similarity(search_ind, words_list.index(word))\n",
    "        vals.append(value)\n",
    "    \n",
    "    vals = np.asarray(vals)\n",
    "    inds = vals.argsort()\n",
    "\n",
    "    return np.asarray(words_stopless)[inds[1:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_implication(search_word, word):\n",
    "    search_ind = words_list.index(search_word)\n",
    "    search_priors = norm_matrix[:,search_ind] > 0\n",
    "    p_b = np.sum(search_priors)\n",
    "    \n",
    "    value_ind = words_list.index(word)\n",
    "    value_priors = norm_matrix[:,value_ind] > 0\n",
    "        \n",
    "    intersect = search_priors * value_priors\n",
    "    p_ab = np.sum(intersect)  \n",
    "    return float(p_ab)/p_b\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_implications(search_word):\n",
    "    search_ind = words_list.index(search_word)\n",
    "    search_priors = norm_matrix[:,search_ind] > 0\n",
    "    p_b = np.sum(search_priors)\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for word in words_stopless:\n",
    "        value_ind = words_list.index(word)\n",
    "        value_priors = norm_matrix[:,value_ind] > 0\n",
    "        \n",
    "        #nk = np.sum(value_priors)\n",
    "        #if (nk == 0):\n",
    "        #    res.append(0)\n",
    "        #    continue\n",
    "        #value_priors = norm_matrix[:,value_ind] * np.log(len(file_in)/float(nk))\n",
    "\n",
    "        intersect = search_priors * value_priors\n",
    "        p_ab = np.sum(intersect)\n",
    "        res.append(float(p_ab)/p_b)\n",
    "        \n",
    "    res = np.asarray(res)\n",
    "    inds = res.argsort()[::-1]\n",
    "    return np.asarray(words_stopless)[inds[1:120]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29386249"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_similarity(words_list.index(\"alcohol\"), words_list.index(\"dowry\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['parties', 'criminal', 'settlement', 'matter', 'dispute',\n",
       "       'offences', 'abuse', 'proceedings', 'quashing', 'emerges',\n",
       "       'arrived', 'honourable', 'process', 'justice', 'continuation',\n",
       "       'quash', 'resolved', 'ends', 'prosecutor'], \n",
       "      dtype='<U17')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_to('settled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73814898419864561"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_implication('gold', 'dowry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['court', 'case', 'counsel', 'high', 'learned', 'also', 'day',\n",
       "       'filed', 'public', 'accused', 'police', 'justice', 'criminal',\n",
       "       'made', 'passed', 'honourable', 'time', 'prosecutor', 'facts',\n",
       "       'come', 'first', 'given', 'offences', 'crime', 'circumstances',\n",
       "       'respondent', 'present', 'matter', 'held', 'petitioner',\n",
       "       'complaint', 'judicial', 'order', 'view', 'complainant', 'petition',\n",
       "       'law', 'parties', 'seen', 'magistrate', 'punishable', 'proceedings',\n",
       "       'considered', 'basis', 'settled', 'light', 'nature', 'report',\n",
       "       'note', 'husband', 'dispute', 'may', 'wife', 'submitted',\n",
       "       'allegation', 'heard', 'state', 'station', 'abuse', 'well',\n",
       "       'conviction', 'said', 'process', 'power', 'though', 'regard', 'fir',\n",
       "       'quash', 'family', 'arrived', 'marriage', 'event', 'trial',\n",
       "       'settlement', 'quashing', 'relevant', 'sought', 'duty', 'apex',\n",
       "       'proceeding', 'interest', 'different', 'decision', 'prosecution',\n",
       "       'reported', 'pertinent', 'personal', 'exercise', 'along',\n",
       "       'jurisdiction', 'result', 'petitioners', 'disputes', 'less',\n",
       "       'allowed', 'file', 'additional', 'carefully', 'code', 'objection',\n",
       "       'decisions', 'involved', 'place', 'specific', 'laid', 'cases',\n",
       "       'proceed', 'grievance', 'prayer', 'position', 'copy', 'amicably',\n",
       "       'affidavit', 'stand', 'entire', 'pending', 'house', 'compromise',\n",
       "       'appears'], \n",
       "      dtype='<U17')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_implications('dowry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_implications_temp(index_words = [], neg_words = [], search_words = words_stopless):\n",
    "    search_priors = np.ones(len(file_in), dtype=np.bool)\n",
    "    \n",
    "    for index_word in index_words:\n",
    "        ind = words_list.index(index_word)\n",
    "        prior = norm_matrix[:, ind] > 0\n",
    "        search_priors = search_priors * prior\n",
    "    \n",
    "    for neg_word in neg_words:\n",
    "        ind = words_list.index(neg_word)\n",
    "        prior = norm_matrix[:, ind] > 0\n",
    "        search_priors = search_priors * (1 - prior)\n",
    "    \n",
    "    p_b = np.sum(search_priors)\n",
    "    \n",
    "    res = []\n",
    "    final = search_priors[:]\n",
    "    \n",
    "    for word in search_words:\n",
    "        value_ind = words_list.index(word)\n",
    "        value_priors = norm_matrix[:,value_ind] > 0\n",
    "\n",
    "        intersect = search_priors * value_priors\n",
    "        final = final * value_priors\n",
    "        p_ab = np.sum(intersect)\n",
    "        res.append(float(p_ab)/p_b)\n",
    "        \n",
    "    res = np.asarray(res)\n",
    "    inds = res.argsort()[::-1]\n",
    "    \n",
    "    if len(search_words) > 10: \n",
    "        return np.asarray(search_words)[inds[1:100]]\n",
    "    else:\n",
    "        return np.asarray(search_words)[inds], res[inds], float(np.sum(final))/p_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_implications_temp(['car'], ['dowry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
